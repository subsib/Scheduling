\documentclass[11pt,a4paper,oneside]{report}
\usepackage[hmargin={1.25in,1.25in},vmargin={1.25in,1.25in}]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\parindent}{0cm}
\makeindex
\usepackage{textcomp}
\usepackage{fancyhdr}
\usepackage{makeidx}
\pagestyle{myheadings}
\fancyhf{}
\rhead[\leftmark]{thepage}
%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{natbib}
\usepackage[T1]{fontenc} % pour taper les lettres accentuées
\usepackage[latin1]{inputenc}
\usepackage[francais]{babel}
\usepackage{url}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfgantt} %draw timechart

\begin{document}
%%%%%%%%%%%%%%%%
%\frontmatter
\begin{titlepage}


\begin{center}
\textbf{UNIVERSITÉ LIBRE DE BRUXELLES}\\
\textbf{Faculté des Sciences}\\
\textbf{Département d'Informatique}
\vfill{}\vfill{}

%\begin{center}
{\Huge  Implementing a Dynamic and Global Scheduling Algorithm  \vspace*{.5cm}  \linebreak[4] in a Real-Time OS}
%\end{center}

{\Huge \par}
\begin{center}{\LARGE Arabella Brayer}\end{center}{\Huge \par}

\vfill{}

\begin{figure}[h]
	\begin{center}
	\includegraphics[width=3cm]{img/sceauquadri}
	\label{fig:sceauquadri}
	\end{center}
\end{figure}
\vfill{}



\begin{flushright}{\large \textbf{Promoteur : Joël Goossens}}\hfill{}{\large Travail préliminaire au mémoire}\\
{
%	 \large Prof. Prénom Nom
 }\hfill{}{\large Master 1}\\
\hfill{}{\large Science de l'informatique}\end{flushright}{\large\par}
\vfill{}\vfill{}\enlargethispage{3cm}
\textbf{Academic year 2016~-~2017}
\end{center}
\end{titlepage}
\newpage
\thispagestyle{empty} 
\null

\newenvironment{vcenterpage}
{\newpage\thispagestyle{empty} 
\vspace*{\fill}}
{\vspace*{\fill}\par\pagebreak}

\newpage
\thispagestyle{empty}
\vspace*{5cm}

\begin{quotation}
\noindent ``\emph{
	%TODO choose a quotation
	Vous pouvez aussi inclure une ou plusieurs citations générales en rapport avec votre sujet.
}''
\begin{flushright}\textbf{l'auteur (vrai ou supposé), date}\end{flushright}
\end{quotation}

\medskip

\begin{quotation}
\noindent ``\emph{Il existe des compilations de telles citations.}''
\begin{flushright}\textbf{autre auteur, date}\end{flushright}
\end{quotation}
%\chapter*{Remerciements}
%\thispagestyle{empty} 

%\noindent Je tiens à remercier ... 

%\medskip
%sans oublier les plus importants, exercice parfois délicat
\thispagestyle{empty} 
\setcounter{page}{0}
\tableofcontents
%\mainmatter 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% chapitre introduction

% TODO trouver meilleur nom qu'introduction, l'introduction est une partie de cette première partie.
\chapter{Introduction}{}
\setcounter{page}{1}
\begin{quotation}
	\noindent ``\emph{certains aiment insérer une ou des citations particulières, en rapport avec le chapitre.}''
	\begin{flushright}\textbf{auteur, date}\end{flushright}
\end{quotation}

\vspace*{0.5cm}

\section{Présentation générale du sujet}
%TODO il FAUT parler des objectifs en terme de réduction de consommation.
%TODO c'est MON dada. 

À l'heure actuelle, les appareils les plus vendus sont les systèmes embarqués.
Parler des IoT.
Le contexte de 
vente et technologique est tel que ce sont des produits avec un potentiel énorme.
Ce qui est étonnant est le décalage existant entre ce pour quoi on a les capacités 
et ce qui existe en réalité : 
dans la théorie, de grands développements existent, avec des schedulers super globaux
efficaces. Dans la pratique, l'industrie boude ces solutions car trop complexes, 
et préfère appliquer une unique solution à tous les systèmes : moins prise de tête.
Mais on est en droit de se dire que ceci ne durera pas.

Dans l'intérêt de la science également, cette question est importante. 

Cela fait plusieurs années que la croissance de l'efficacité des appareils n'est plus 
principalement due à des améliorations physiques des composants. 
En effet, la multiplication des processeurs dans les ordinateurs a permis
de paralléliser et c'est ainsi que la quasi stagnation des 
technologies a pu être contournée pour continuer la progression.\\
% TODO add ref du cours de micro

Le monde des systèmes embarqués en temps réel a bénéficié de ces améliorations également, 
et dispose très souvent de processeurs multi-c?urs. Cependant, leur gestion n'est 
à l'heure actuelle pas optimale, la plupart des systèmes sont simplement 
gérés soit comme des systèmes mono-processeurs, soit partitionnés.
Si la littérature autour des ordonnanceurs en temps réels illustre abondamment l'intérêt de l'intégration de cette parallélisation, 
les faits montrent plutôt que les industries continuent d'implémenter des solutions mono-processeur. 

Ceci peut s'expliquer en partie par le fait qu'il soit 
compliqué de gérer le partage des ressources, et que cette complexité 
n'apporte pas suffisamment d'avantages à l'heure qu'il est en terme de 
réduction de consommation énergétique ou simplement en efficacité.\\

Il en résulte un décalage entre les connaissances théoriques et pratiques 
de ces ordonnanceurs. 
C'est dans ce contexte que s'inscrit ce travail d'implémentation d'un ordonnanceur en temps réel 
global et multiprocesseur, dont un des objectifs est d'améliorer la connaissance pratique 
d'ordonnanceurs multiprocesseurs globaux, d'en apercevoir les limites. 
Cette implémentation pourrait amener plusieurs résultats intéressants : \\
\begin{itemize}
	\item Une comparaison entre des résultats théoriques et l'effet de leur mise 
	en \oe{}uvre
	\item L'origine de ces différences
	\item Vérifier les avantages, inconvénients ou obstacles à la 
	commercialisation de telles solutions.
\end{itemize}

\section{Contexte et objectifs}
\subsection{Ordonnanceurs globaux}



Depuis la preuve qu'aucun ordonnanceur global optimal n'existe pour toutes les classes 
de tâches,
[Hong and Leung \cite{hongandleung}, 1988] plusieurs candidats 
ordonnanceurs avec des propriétés différentes ont été proposés. 
Toutefois, ils sont encore assez peu utilisés actuellement dans l'industrie.\\

On peut cependant imaginer que la situation évolue dans les prochaines années. 
En effet, les systèmes embarqués vont également nécessiter de la puissance de calcul et
de l'efficacité. Les contraintes de partage de ressources se posent différemment 
dans le cas parallélisé, avec des contraintes d'accès à ces dernières, 
donc plus de complexité mais celle-ci pourrait en contrepartie apporter 
bien plus de performance.

%TODO pourquoi pas GPU ???

Le fait que l'industrie n'implémente pas à ce jour de solutions plus performantes 
pour les systèmes embarqués pose plusieurs problèmes :
\begin{enumerate}
	\item Le matériel n'est pas exploité de façon optimale.
	\item Par conséquent, on utilise bien plus d'énergie que nécessaire. 
	À l'heure actuelle, dans un monde où l'on cherche à consommer le moins possible, 
	cela pose question. Mais au delà, cela signifie également plus de maintenance 
	sur ces appareils parfois sans source de renouvellement d'énergie.
	\item Certains systèmes embarqués nécessitent une très basse consommation car 
	ils sont difficiles d'accès ou non faciles à recharger.
\end{enumerate}

Toutes ces raisons poussent à s'intéresser à une implémentation réelle et réaliste 
d'ordonnanceur connu dans la littérature, mais moins dans la réalité.

\subsection{HIPPEROS}
\textbf{HIPPEROS} (High Performance Parallel Embedded Real-time Operating Systems)
est un \textbf{RTOS} développé depuis plusieurs années par une spinoff de l'ULB.
Il bénéficie des connaissances apportées par le monde de la recherche dans 
le domaine des systèmes critiques avec multic\oe{}urs. Une de ses particularités 
est sa modularité, qui permet d'adapter ses possibilités en fonction du système 
lors de la compilation de l'OS, ainsi peut-on différencier deux installations 
en fonction des particularités.

\textbf{HIPPEROS} est un candidat idéal pour l'implémentation d'un ordonnanceur 
global, mais une partie du travail consistera à tirer parti de ses particularités. 
Par exemple, ce système d'exploitation gère les c\oe{}urs en leur attribuant des 
niveaux différents. L'un est considéré comme "maître" et les autres comme "esclaves". 
Ceci peut apporter un comportement particulier, ce auquel il convient d'apporter 
l'attention nécessaire. En résumé, une nouvelle implémentation sur un OS différent 
peut elle-aussi apporter à la connaissance générale des détails importants.


\section{Problématique}
L'ordonnanceur idéal, c'est à dire optimal pour toute classe de tâche n'existant pas, 
une partie du problème est donc de sélectionner l'un de ceux-ci parmi la liste 
d'ordonnanceurs connus (ne serait-ce que littérairement) afin que cela apporte 
à la connaissance générale, tant théorique que pratique.

Par ailleurs, pour certains des ordonnanceurs qui seront présentés dans l'état de l'art, 
certains ont déjà bénéficié d'une implémentation sur un \textbf{RTOS}. 
Il peut être également intéressant d'étudier la différence d'implémentation 
sur des OS différents, ainsi que les résultats obtenus. 
En effet, il est tout à fait possible que 


D'autre part, ils sont décrits dans la littérature de façon parfaitement théorique. Certains ont bénéficié d'une implémentation en \textbf{linux rt}. %TODO add ref
Mais alors, sur un autre ordonnanceur peut se poser le problème de la reproductibilité. 
Certains ordonnanceurs font des hypothèses fortes et le comportement réel pourrait 
être fort différent de celui décrit dans la littérature. 
Ces sujets seront évoqués dans l'état de l'art. %TODO verif que c'est fait

La question cruciale de cette première partie de travail 
consiste donc à faire un tour d'horizon de la littérature afin de pouvoir 
sélectionner un ordonnanceur pertinent à implémenter sur le \textbf{RTOS} \textbf{HIPPEROS}.

\section{Vocabulaire général sur les systèmes temps réel}

\subsection{RTOS}
(Real Time Operating System) Système d'Exploitation Temps Réel.\\
	Un système d'exploitation Temps Réel est implémenté dans des systèmes à temps réel. 
	Il s'agit globalement de systèmes embarqués critiques, comme il en existe à ce jour 
	énormément (dans les avions, comme systèmes de contrôles, dans les voitures, etc.).
	Les contraintes ne sont pas les mêmes que dans un OS (\textbf{O}perating \textbf{S}ystem, Système d'Exploitation) classique, particulièrement pour
	l'ordonnanceur. 
	En effet, celui-ci doit gérer un ensemble de tâches qui doivent 
	(impérativement, ou pas) respecter des temps limites. 
	Attention cependant à ne pas confondre le besoin de synchronisation avec le besoin de rapidité : 
	tous les systèmes à temps réel n'ont pas forcément besoin de vitesse. 
	
	Il faut néanmoins s'assurer que tous les délais peuvent être respectés, et 
	c'est là une partie très importante du travail avant de mettre sur le 
	marché un système embarqué.\\
	%TODO https://fr.wikipedia.org/wiki/Syst%C3%A8me_d%27exploitation_temps_r%C3%A9el
	
\subsection{Contraintes strictes, contraintes relatives} 
Dans le cas strict, le système doit impérativement respecter tous les temps limites. Aucun dépassement n'est toléré. Dans le cas des contraintes relatives, ce respect 
est moins impératif, et on pourra dépasser les délais occasionnellement. \\

\subsection{Tâche (temps réel)}
Une tâche correspond à une sorte de programme, c'est à dire une série d'instructions 
qui doivent être exécutées par un processeur. 
Il y a plusieurs caractéristiques 
et propriétés qui définissent une tâche, que nous allons définir ici : 
\begin{itemize}
	\item[\textbf{Release Time}] : C'est le moment $t$ où une tâche $\tau$ peut commencer à être exécutée.
	\item[\textbf{Start, End}] : Le moment où la tâche commence effectivement à être exécutée, ou termine son exécution.
	\item[\textbf{Response Time\label{Response Time}}] : Temps maximum nécessaire à la réalisation de la tâche 
	entre le Release Time et End. %TODO vérif
	\item[\textbf{Deadline, temps limite}] : Correspond au temps limite au delà duquel la tâche doit avoir été exécutée. Il existe deux types de deadlines : 
	une absolue, et une relative. La deadline relative est une valeur fixe qui 
	est une propriété de la tâche, elle dépend donc du release time.\\
	La deadline absolue quant à elle est calculée avant l'exécution, et correspond 
	à un temps $t$ absolu.%TODO explain better, relire cours ptete ?!
	
	\item[\textbf{Worst Case Execution Time}] Afin de faciliter les calculs et l'abstraction du problème, l'on pose habituellement que le temps considéré d'exécution de 
	la tâche est le pire temps. Cela permet d'envisager le pire scénario, et ainsi 
	de s'assurer que si celui-ci est possible, alors dans de meilleures conditions, 
	la faisabilité est conservée. La notation utilisée dans le reste de ce document 
	est  \textbf{WCET} : \textbf{W}orst \textbf{C}ase \textbf{E}xecution \textbf{T}ime
	
	\item[\textbf{Laxité}] La laxité d'une tâche est la durée entre sa réalisation et son échéance. 
	Pour une tâche $\tau_i$, la laxité est :
	\begin{center}
		$L_i = D_i - C_i$
	\end{center}
\vspace{0.5cm}
	\item[\textbf{Tâches périodiques}]
	Une tâche périodique est une tâche qui génère régulièrement des jobs.  
Formellement, une tâche périodique est définie par un 4-uplet $(O, T, D, C)$ où 
\begin{itemize}
	\item[O] est l'"offset", c'est à dire le temps que met la tâche à générer un premier job.
	\item[T] est la période, c'est à dire le temps qui sépare deux générations de job par la tâche. 
	Comme le premier job est généré à l'instant $O$, alors $\forall i \in \{0, \infty \} t = O + i\times T$ 
	où $t$ est le temps où la tâche est générée la $i$ème fois.
	\item[D] est la deadline relative, c'est à dire le temps qui sépare au maximum la génération 
	d'un job et sa réalisation.
	\item[C] est le temps de réalisation. Dans les algorithmes, on utilise -- comme expliqué précédemment --
	le \textbf{WCET}.
\end{itemize}	
	Dans le cas de tâches périodiques, on distingue trois cas différents : \\
	\begin{enumerate}
		\item si l'échéance est égale à la période $\forall \tau_i, D_i = T_i$ : tâche à \label{echeancesurrequete}échéance sur requête
		\item si l'échéance est inférieure ou égale à la période $\forall \tau_i, D_i \leq T_i $ , on dit que la tâche est à \label{echeancecontrainte} échéance contrainte
		\item s'il n'y a pas de contrainte particulière, la tâche est dite "à échéance arbitraire".
	\end{enumerate}
	Les solutions d'ordonnancement pour ces trois types de tâches diffèrent donc. 
	Globalement, on peut ordonner ces trois types de tâches : \\
	échéance sur requêtes $\subset$ échéance contrainte $\subset$ échéance arbitraire.
	
	\item[\textbf{Tâche sporadique}] : Une tâche est sporadique est une tâche qui génère de nouveaux jobs, 
	comme dans le cas de la tâche périodique. 
	La différence entre ces deux types est que la tâche sporadique 
	génère deux jobs avec un intervalle de temps au moins égal à la durée correspondant à sa période, 
	et pas exactement égal. 
	
	\item[\textbf{Tâche apériodique}] : Pour ce type de tâches, on ignore la régularité de 
	l'arrivée de nouveaux jobs. Les propriétés du job ne sont connues que lorsqu'un job est 
	généré dans le système.
	
\end{itemize}

\subsection{Job}
Un job est une instance d'une tâche. %TODO fill...

\subsection{Ordonnanceur}
Un ordonnanceur (Scheduler) est la partie logicielle de 
l'OS chargée d'orchestrer l'ordre d'exécution des tâches du système 
selon des priorités fixées à l'avance ou durant l'exécution. 
On distingue trois types d'assignation de priorités des ordonnanceurs : \\
\begin{enumerate}
	\item Priorité fixée au niveau des tâches : Ce type d'ordonnanceur fixe la priorité 
	avant l'exécution, et celle-ci dépend donc des attributs de la tâche. 
	Deux exemples d'ordonnanceurs de ce type seront présentés plus loin : Rate Monotonic et 
	Deadline Monotonic.
	\item Priorité fixe au niveau des jobs : La priorité est fixée par l'ordonnanceur à l'arrivée du job 
	dans l'exécution, et elle ne peut pas changer jusqu'à la réalisation du job. Un exemple sera présenté plus loin : Earliest Deadline First.
	\item Priorité dynamique : L'ordonnanceur peut recalculer à tout moment de l'exécution 
	la priorité du job avec un exemple connu, Least Laxity First %TODO add ref
\end{enumerate}
	
Selon les cas, l'ordonnanceur peut avoir à gérer un seul processeur. Dans ce 
document, on parlera dans ce cas d'ordonnanceur mono-processeur. Toutefois, de plus en 
plus de systèmes possèdent plusieurs processeurs, et il existe deux grandes familles 
d'ordonnanceurs associés à ces systèmes : les Partitionnés, ou les Globaux. \\

%\subsection{En ligne, hors ligne}
%TODO blabla

\subsubsection{Ordonnanceur multi-processeur Partitionné}
Dans ce cas de figure, un traitement hors ligne aura permis de diviser/partitionner 
les tâches en des ensembles selon certaines propriétés. Par la suite, le traitement 
est similaire à un ordonnanceur mono-processeur.

\subsubsection{Ordonnanceur multi-processeur Global}
Ici, le traitement "idéal" se fait en ligne entièrement, le système gère directement 
plusieurs processeurs et un système de tâches. Ces ordonnanceurs sont par 
conséquents plus complexes, et par ailleurs, comme il a été précisé plus haut dans 
ce document, l'ordonnanceur global qui peut orchestrer n'importe quel ensemble de 
tâche optimal n'existe pas.

Dans la littérature, on décrit des ordonnanceurs dont une partie du travail se fait 
hors ligne (RUN) %TODO add ref
et on parle alors d'ordonnanceur "hybride".
	
\subsection{Préemption et hypothèse} 
Un système est dit préemptif s'il a la capacité 
	de mettre l'exécution d'un job en pause et d'exécuter un autre à la place. 
	Une hypothèse pour simplifier la question théorique des ordonnanceur est 
	très souvent faite dans la littérature : on considère le temps de 
	préemption comme nul. Cette hypothèse est bien entendu fausse, et il faudra 
	en tenir compte, particulièrement dans ce travail où l'on tente de faire 
	le lien entre la théorie et la mise en pratique. 

\subsection{Utilisation}
Le facteur d'utilisation $U_i$ d'une tâche périodique $\tau_i$ est le rapport entre 
son temps d'exécution et sa période. Par exemple, pour une tâche $\tau_i$ tel que 
$WCET = 50 ms$ et $T = 30 ms$, le processeur doit allouer $\frac{30}{50}$ du temps 
total d'exécution à cette tâche.\\

L'utilisation (ou le facteur d'utilisation) d'un système périodique est la proportion de temps 
passée par le processeur à l'exécution de tâches d'un système donné. 
Le calcul de l'utilisation permet dans certains cas et certaines conditions de donner une indication 
à propos de la faisabilité du système par un certain ordonnanceur. 
\\

Liu et Layland \cite{liulayland} en donnent une définition formelle dans leur article décrivant 
l'ordonnanceur \textbf{Rate Monotonic} (présenté plus tard dans ce document).\\ 

Soit $C_i$ le temps d'exécution d'une tâche $\tau_i$, et soit $T_i$ sa période, voici la définition de 
l'utilisation pour un système de $m$ tâches :\\
\begin{center}
	$U_{tot} = \sum_{i = 1}^{m}(\frac{C_i}{T_i})$
\end{center}


\subsection{Représentation graphique d'un système}
%TODO fill with an example. Hope not to have to draw it in latex :/

\begin{ganttchart}[vgrid, hgrid]{1}{15}
	\ganttbar{$\tau_1$}{7}{9}\\
	\ganttbar{$\tau_2$}{2}{4}\\
	\ganttbar{$\tau_3$}{5}{6}\\
	\ganttbar{$\tau_4$}{10}{10}\\
	\ganttbar{$\tau_5$}{11}{13}
\end{ganttchart}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% ETAT DE L'ART %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%
%
%%%%%%%%%%%%%%%%%
%\part{Si du moins votre travail est divisé en parties}
%%%%%%%%%%%%%%%%%
\chapter{État de l'art}

La littérature sur le sujet des ordonnanceurs est assez vaste. 
Ceux-ci sont composés principalement de trois grandes familles :\\
\begin{itemize}
	\item Les mono-processeurs
	\item Les multi-processeurs Partitionnés
	\item Les multiprocesseurs Globaux
\end{itemize}
Les ordonnanceurs mon-processeurs étant plus simples à appréhender, nous commencerons 
par présenter cette famille.

\section{Ordonnanceurs mono processeur}

\subsection{Rate Monotonic}
L'ordonnanceur \textbf{R}ate \textbf{M}onotonic (RM) est décrit la première fois par Liu et Layland \cite{liulayland} en 1973. C'est 
donc un ordonnanceur classique, bien connu, ainsi que largement documenté [\cite{omarkermia}]. 
On considère un ensemble de tâches périodiques et indépendantes.
Les priorités sont statiques et attribuées en fonction de la durée de la période, ainsi 
la tâche avec la période la plus faible sera de priorité plus élevée. 
Un des points fondamentaux de l'article est de prouver l'optimalité de RM dans le cas de tâches 
préemptives, périodiques (à échéance sur requête), indépendantes, simultanées.
Les auteurs énoncent même une condition suffisante de faisabilité pour un système à $m$ tâches : \\
\begin{center}
	$\sum_{i=1}^{m}\frac{C_i}{T_i} \leq m(2^{\frac{1}{m}}-1)$
\end{center}
Notons également que pour $n \rightarrow \infty$, $\sum_{i=1}^{m}\frac{C_i}{T_i} \leq m(2^{\frac{1}{m}}-1) \rightarrow \ln(2) \approx 0.69$.
Une condition suffisante est donc que le facteur d'utilisation du système soit inférieur à 0.69. 
Dans ce cas, le système est ordonnançable par RM.\\

Des améliorations ont par la suite été apportées par Joseph et Pandya \cite{DBLP}.
qui ont trouvé une condition nécessaire et suffisante. 
Ainsi, si $RT(t_i)$ est le Response Time (\ref{Response Time}) d'une tâche $t_i$, 
alors si un ensemble de tâches périodiques est trié par ordre décroissant, l'équation suivante 
définit la borne supérieure du Release Time :
\begin{center}
	$RT(t_i)^{q+1} = \sum_{j=1}^{i-1} \lceil \frac{RT(t_i)^q}{T(t_i)} \rceil \times C(t_j)) + C(t_i)$
\end{center}
Le système est ordonnançable si et seulement si $\forall i_{(1 \leq i \leq m)}RT(t_i) \leq T_i$.
On pourra résoudre récursivement cette équation afin de prouver sa faisabilité.\\

RM n'est cependant optimal que pour cette classe de tâches. Dès que les propriétés changent, 
il faudra se tourner vers un autre type d'ordonnanceur.


\subsection{Deadline Monotonic}
Deadline Monotonic (DM) est un ordonnanceur pour les systèmes à départ simultanés ($offset = 0$) et 
à échéance contrainte\ref{echeancecontrainte}($D_i \leq T_i$). Il a été décrit par Leung et Whitehead 
\cite{LeungW82}. Cet article aborde le point de vue mono-processeur et multi-processeur partitionné, 
dont il sera question plus loin dans ce document.\\

Avec cet ordonnanceur, les priorités sont fixes, au niveau des tâches.
Plus la deadline est petite, plus la priorité est élevée. On peut considérer que RM est 
un cas particulier de DM, puisque pour RM, les tâches sont à échéance sur requête \ref{echeancesurrequete}.
Il n'existe pas de test de faisabilité basé sur l'utilisation du système. Pour vérifier celle-ci, 
il faut avoir recours à l'équation décrite plus haut. 
On peut la résoudre récursivement à l'aide de ce système : \\
\begin{enumerate}
	\item $W_0 = C_i $
	\item $W_{k+1} = C_i + \sum_{j = 1}^{i-1}\lceil \frac{W_k}{T_j} \rceil \times C_j $
\end{enumerate}



\subsection{Earliest Deadline First}
\cite{ndoye}
\textbf{E}arliest \textbf{D}eadline \textbf{F}irst (EDF) est un ordonnanceur 
qui a été introduit e 1973, à la même période que Rate Monotonic, également 
par Lui et Layland \cite{liulayland}. C'est un ordonnanceur à départ différé ($Offset \neq 0$) 
et à deadline arbitraire (pas de contrainte sur la deadline par rapport à la période), 
qui fixe les priorités sur les jobs. L'assignation de la priorité se fait sur base de 
la proximité de la deadline absolue : Plus cette deadline est proche et plus la priorité est élevée. 
Une façon déterministe et arbitraire de régler les cas d'égalité doit être décidée.\\

EDF est optimal pour toutes les tâches synchrones et asynchrones, avec et sans 
contraintes sur les deadlines. 
Cela signifie que si un système est ordonnançable, EDF peut l'ordonnancer.\\
Cette propriété est importante, car les classes de tâches ordonnancées par EDF 
sont plus larges que RM et DM, par conséquent, EDF peut ordonnancer également les 
mêmes classes qu'RM et DM en conservant son optimalité. \\

Les tests de faisabilités avec EDF dépendent de la classe de tâche considérée. 
Pour un système synchrone et à échéance sur requête, 
une condition nécessaire et suffisante de faisabilité est donc que l'utilisation soit inférieure 
à 100\%, c'est à dire : \\
\begin{center}
	$\forall \tau_i \in \Gamma_m, \sum_{i=1}^{m}\frac{C_i}{T_i} \leq 1 $
\end{center}

Dans le cas d'un système synchrone à échéance arbitraire, on doit considérer un intervalle de 
recherche $[0, L]$ avec $L$ qui peut se calculer de façon itérative en cherchant un point fixe 
avec cette formule : \\
\[
\left \{
\begin{array}{r l}
W_0 &= \sum_{i = 1}^{m}C_i\\
W_{k+1} & =\sum_{i = 1}^{m} \lceil \frac{W_k}{T_i} \rceil \times C_i
\end{array}
\right.
\]

Dans le cas des systèmes de tâches asynchrones, l'intervalle considéré est plus grand : 
$[0, O_{max} + 2 \times P]$ avec $O_{max}$ l'offset maximum du système et 
$P$ le plus petit commun multiple ($ppcm$) de toutes les périodes du système, soit : \\
\begin{center}
	$P = ppcm\{T_i | i \in \{1, ... m\}\}$
\end{center}

\section{Multi-processeurs partitionnés}

%TODO revoir cours de goossens

Dans la section précédente, plusieurs ordonnanceurs mono-processeurs ont été présentés. 
C'est une simplification qui permet de comprendre comment fonctionne un ordonnanceur temps 
réel, mais bien entendu, dans la réalité, beaucoup de systèmes fonctionnent avec plusieurs processeurs. 
Dans ce cas, la complexité augmente, et les propriétés vues précédemment ne sont pas conservées. \\
%TODO insert test faisabilité ssi multiproc

La première idée, pour ordonnancer un système sur plusieurs processeurs, est de partitionner 
l'ensemble de tâches en plusieurs systèmes de sorte de pouvoir appliquer les algorithmes 
vus plus haut. Ceci permet d'appliquer les tests de faisabilité. \\

Le problème du partitionnement (bin-packing) %TODO ref
appartient à la classe de complexité $NP$, si bien qu'en pratique, 
des heuristiques sont appliquées : 

\section{Multi-processeurs globaux}
Une autre façon d'ordonnancer plusieurs processeurs est de ne pas procéder à un partitionnement préalable, 
et donc, de gérer tous les processeurs en même temps. 
Les deux façons de procéder ne sont pas comparables. Pourquoi ?
--> parler de il n'existe pas de scheduler non clairvoyant optimal.
Résultat super important, cité avant.\\

Donc il n'existe pas de test qui permette de savoir si on peut ordonnancer 
un système sur partionned ou global.

Ca signifie qu'il faut essayer de le faire... Simuler.

Problèmeh : les deux façons de procéder sont incaparables. Pourquoi ? Issu du cours, montrer 
un système schedulable en partionned et pas en global et vice et versa.

Grande idée : il existe PAS de scheuler idéal.
Du coup, il faut en chercher un qui a le plus grand système de tâche possible, ou du moins, 
le plus intéressant. 

Parmi ceux-ci, il y a : 

% parler pb de partage des ressources


\subsection{EDF-k}

\section{Conclusion}
% tableau ? Support pour développer argumentation ?

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}


