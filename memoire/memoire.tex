\documentclass[11pt,a4paper,oneside]{report}
\usepackage[hmargin={1.25in,1.25in},vmargin={1.25in,1.25in}]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\parindent}{0cm}
\makeindex
\usepackage{textcomp}
\usepackage{fancyhdr}
\usepackage{makeidx}
\pagestyle{myheadings}
\fancyhf{}
\rhead[\leftmark]{thepage}
%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{natbib}
\usepackage[T1]{fontenc} % pour taper les lettres accentuées
%\usepackage[latin1]{inputenc}
\usepackage[UTF8]{inputenc}
\usepackage[francais]{babel}
\usepackage{url}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfgantt} %draw timechart
\newtheorem{mydef}{Définition}

\begin{document}
%%%%%%%%%%%%%%%%
%\frontmatter
\begin{titlepage}


\begin{center}
\textbf{UNIVERSITÉ LIBRE DE BRUXELLES}\\
\textbf{Faculté des Sciences}\\
\textbf{Département d'Informatique}
\vfill{}\vfill{}

%\begin{center}
{\Huge  Implementing a Dynamic and Global Scheduling Algorithm  \vspace*{.5cm}  \linebreak[4] in a Real-Time OS}
%\end{center}

{\Huge \par}
\begin{center}{\LARGE Arabella Brayer}\end{center}{\Huge \par}

\vfill{}

\begin{figure}[h]
	\begin{center}
	\includegraphics[width=3cm]{img/sceauquadri}
	\label{fig:sceauquadri}
	\end{center}
\end{figure}
\vfill{}



\begin{flushright}{\large \textbf{Promoteur : Joël Goossens}}\hfill{}{\large Travail préliminaire au mémoire}\\
{
%	 \large Prof. Prénom Nom
 }\hfill{}{\large Master 1}\\
\hfill{}{\large Science de l'informatique}\end{flushright}{\large\par}
\vfill{}\vfill{}\enlargethispage{3cm}
\textbf{Academic year 2016~-~2017}
\end{center}
\end{titlepage}
\newpage
\thispagestyle{empty} 
\null

\newenvironment{vcenterpage}
{\newpage\thispagestyle{empty} 
\vspace*{\fill}}
{\vspace*{\fill}\par\pagebreak}

%\newpage
%\thispagestyle{empty}
%\vspace*{5cm}

%\begin{quotation}
%\noindent ``\emph{
%	%TODO choose a quotation
%	Vous pouvez aussi inclure une ou plusieurs citations générales en rapport avec votre sujet.
%}''
%\begin{flushright}\textbf{l'auteur (vrai ou supposé), date}\end{flushright}
%\end{quotation}

%\medskip
%
%\begin{quotation}
%\noindent ``\emph{Il existe des compilations de telles citations.}''
%\begin{flushright}\textbf{autre auteur, date}\end{flushright}
%\end{quotation}
%\chapter*{Remerciements}
%\thispagestyle{empty} 

%\noindent Je tiens à remercier ... 

%\medskip
%sans oublier les plus importants, exercice parfois délicat
\thispagestyle{empty} 
\setcounter{page}{0}
\tableofcontents
%\mainmatter 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% chapitre introduction

% TODO trouver meilleur nom qu'introduction, l'introduction est une partie de cette première partie.
\chapter{Introduction}{}
\setcounter{page}{1}


\section{Présentation générale du sujet}
%TODO il FAUT parler des objectifs en terme de réduction de consommation.
%TODO c'est MON dada. 

Dans le paysage quotidien des appareils informatiques, il existe toujours plus de systèmes embarqués. 
Parmi eux, un nombre très important de systèmes temps réel qui nécessitent des 
ordonnanceurs adaptés. Ce champ scientifique a été largement fourni durant les 
vingt dernières années par de nombreuses publications scientifiques. \\

Les systèmes embarqués n'ont pas toujours de grands besoins en efficacité, 
ils doivent principalement être sûrs, et réactifs. 
Toutefois, un système "non efficace" n'utilise pas ses ressources de façon optimale. 
De nos jours où la gestion énergétique se doit d'être la plus économe possible, 
où l'efficacité des appareils est de plus en plus exigée, il est envisageable que 
la solution évolue du côté des industries.\\

Par ailleurs, cela fait plusieurs années que la croissance de l'efficacité des appareils n'est plus 
principalement due à des améliorations physiques des composants. 
En effet, la multiplication des processeurs dans les ordinateurs a permis
de paralléliser les exécutions, et c'est ainsi que la quasi stagnation des 
technologies a pu être contournée pour continuer la progression.
% TODO add ref du cours de micro

Le monde des systèmes embarqués en temps réel a bénéficié de ces améliorations, 
et dispose également de processeurs multi-c\oe{}urs. Cependant, leur gestion n'est 
à l'heure actuelle pas optimale, la plupart des systèmes sont  
gérés soit comme des systèmes mono-processeurs, soit avec des algorithmes partitionnés \cite{paolillo_new_nodate}. 
Dans le premier cas, les ressources ne sont pas utilisées de façon optimales, 
et dans le second, des implémentations et tests ont montré empiriquement 
que les algorithmes globaux pouvaient présenter des avantages intéressants, comme 
une meilleure répartition de l'utilisation des processeurs. 
\\ %TODO vérif ça, c'est pas correct
%TODO https://pdfs.semanticscholar.org/64df/4e9ecf8c2a22595d7c9bc0f8814c4445a614.pdf

Le décalage entre la connaissance scientifique et les implémentations réelles 
peut s'expliquer en partie par le fait qu'il soit compliqué de gérer le partage des ressources, 
et que cette complexité n'apporte pas suffisamment d'avantages à l'heure qu'il est.\\

Le fait que l'industrie n'implémente pas à ce jour de solutions plus "performantes" 
pour les systèmes embarqués pose plusieurs problèmes :
\begin{enumerate}
	\item Le matériel n'est pas exploité de façon optimale.
	\item Par conséquent, on utilise bien plus d'énergie que nécessaire. 
	À l'heure actuelle, dans un monde où l'on cherche à consommer le moins possible, 
	cela pose question. Mais au delà, cela signifie également plus de maintenance 
	sur ces appareils parfois sans source de renouvellement d'énergie.
	\item Certains systèmes embarqués nécessitent une très basse consommation car 
	ils sont difficiles d'accès ou non faciles à recharger.
\end{enumerate}

Toutes ces raisons poussent à s'intéresser à une implémentation réelle et réaliste 
d'ordonnanceur connu dans la littérature, mais moins dans la réalité.

C'est dans ce contexte que s'inscrit ce travail d'implémentation d'un ordonnanceur en temps réel 
global et multiprocesseur, dont un des objectifs est d'améliorer la connaissance pratique 
d'ordonnanceurs multiprocesseurs globaux, d'en apercevoir les limites. 
Cette implémentation pourrait amener plusieurs résultats intéressants : \\
\begin{itemize}
	\item Une comparaison entre des résultats théoriques et l'effet de leur mise 
	en \oe{}uvre
	\item L'origine de ces différences
	\item Vérifier les avantages, inconvénients ou obstacles à la 
	commercialisation de telles solutions.
\end{itemize}

\section{Contexte et objectifs}

%\subsection{Limites du parallélisme}
%Le parallélisme a montré ses limites, connues depuis longtemps dans la littérature scientifique. 
%Par exemple, la loi d'\href{https://en.wikipedia.org/wiki/Amdahl\%27s_law}{Amdahl} montre 
%l'accélération théorique que l'on peut atteindre en améliorant certains paramètres : 
%%TODO mettre une référence correcte
%\begin{itemize}
%    \item La portion de code exécutable en parallèle (tout un programme séquentiel ne peut pas forcément 
%    être parallélisable)
%    \item Le nombre de processeurs. 
%\end{itemize}
%On remarque alors que le nombre de processeurs n'influence la vitesse d'exécution que jusqu'à une certaine limite 


\subsection{Ordonnanceurs globaux}
Comme il sera expliqué plus tard dans ce document, il existe deux grandes familles d'ordonnanceurs 
multiprocesseur :\\
\begin{itemize}
	\item Les ordonnanceurs partitionnés
	\item Les ordonnanceurs globaux
\end{itemize}
Si parmi ces deux familles d'ordonnanceurs, les systèmes mono-processeurs, voire 
partitionnés ont le plus de succès auprès de l'industrie, 
ce n'est pas la famille la plus efficace pour tout type de classe de tâches. 
Les algorithmes globaux répartissent habituellement mieux l'utilisation des processeurs, 
les migrations sont possibles et donc les temps de réalisation sont généralement moins grands.
\\ % TODO add ref ?... J'ai une conf, mais pas un papier scientifique...
% http://retis.sssup.it/~giorgio/slides/cbsd/mc3-global-2p.pdf


En 1988, Hong and Leung \cite{hong_-line_1988} publient un article dans lequel est 
démontré que : \\
\textit{"For every m > 1, no optimal on-line scheduler can exist for task systems with two or more distinct deadlines"} : 
\textit{Il n'existe pas d'ordonnanceur multiprocesseur en ligne optimal pour un système de tâches 
avec plusieurs échéances distinctes}, donc un système de tâches dites "sporadiques".

Or, les systèmes embarqués doivent très souvent exécuter des systèmes de tâches sporadiques, 
cela tient de leur nature : la plupart d'entre eux attendent en effet de recevoir des 
signaux, qui arrivent de façon indéterminée.

Toutefois, des publications ultérieures viennent compléter cette preuve, et démontrent 
que des ordonnanceurs globaux optimaux existent, mais nécessitent de la clairvoyance.
%TODO add ref gossens




\subsection{HIPPEROS}
\textbf{HIPPEROS} (High Performance Parallel Embedded Real-time Operating Systems)
est un \textbf{RTOS} développé depuis plusieurs années par une spinoff de l'ULB.
Il bénéficie des connaissances apportées par le monde de la recherche dans 
le domaine des systèmes critiques avec multic\oe{}urs. Une de ses particularités 
est sa modularité, qui permet d'adapter ses possibilités en fonction du système 
lors de la compilation de l'OS, ainsi peut-on différencier deux installations 
en fonction des particularités.

\textbf{HIPPEROS} est un candidat idéal pour l'implémentation d'un ordonnanceur 
global, mais une partie du travail consistera à tirer parti de ses particularités. 
Par exemple, ce système d'exploitation gère les c\oe{}urs en leur attribuant des 
niveaux différents. L'un est considéré comme "maître" et les autres comme "esclaves". 
Ceci peut apporter un comportement particulier, ce auquel il convient d'apporter 
l'attention nécessaire. En résumé, une nouvelle implémentation sur un OS différent 
peut elle-aussi apporter à la connaissance générale des détails importants.


\section{Problématique}
L'ordonnanceur idéal, c'est à dire optimal pour toute classe de tâche n'existant pas, 
une partie du problème est donc de sélectionner l'un d'eux parmi une liste 
d'ordonnanceurs connus (ne serait-ce que dans la littérature) afin que cela apporte 
à la connaissance générale, tant sur le plan théorique que pratique.

Par ailleurs, certains des ordonnanceurs présentés dans l'état de l'art 
 ont déjà bénéficié d'une implémentation sur un \textbf{RTOS}, et une nouvelle 
 implémentation sur un \textbf{OS} différent pourrait apporter un éclairage intéressant quant 
 aux différences de comportements.
Dans certaines présentations d'ordonnanceurs sont proposées des hypothèses à propos du comportement, 
comme faire globalement plus de préemption, de migrations. 
Le comportement observé dans des conditions différentes pourrait être vérifié, ou le contraire.

La question cruciale de cette première partie de travail 
consiste donc à faire un tour d'horizon de la littérature afin de pouvoir 
sélectionner un ordonnanceur pertinent à implémenter sur le \textbf{RTOS} \textbf{HIPPEROS}.

\section{Vocabulaire général sur les systèmes temps réel}

\subsection{RTOS}
\begin{mydef}
(Real Time Operating System) Système d'Exploitation Temps Réel.\\
Un système d'exploitation Temps Réel est implémenté dans des systèmes à temps réel. 
Il s'agit globalement de systèmes embarqués critiques, comme il en existe à ce jour 
énormément (dans les avions, comme systèmes de contrôles, dans les voitures, etc.).
Les contraintes ne sont pas les mêmes que dans un OS (\textbf{O}perating \textbf{S}ystem, Système d'Exploitation) classique, particulièrement pour
l'ordonnanceur. 
En effet, celui-ci doit gérer un ensemble de tâches qui doivent 
(impérativement, ou pas) respecter des temps limites. 
Attention cependant à ne pas confondre le besoin de synchronisation avec le besoin de rapidité : 
tous les systèmes à temps réel n'ont pas forcément besoin de vitesse. 

Il faut néanmoins s'assurer que tous les délais peuvent être respectés, et 
c'est là une partie très importante du travail avant de mettre sur le 
marché un système embarqué.\\
%TODO https://fr.wikipedia.org/wiki/Syst%C3%A8me_d%27exploitation_temps_r%C3%A9el

\end{mydef}
	
\subsection{Contraintes strictes, contraintes relatives} 
Dans le cas strict, le système doit impérativement respecter tous les temps limites. Aucun dépassement n'est toléré. Dans le cas des contraintes relatives, ce respect 
est moins impératif, et on pourra dépasser les délais occasionnellement. \\

\subsection{Tâche (temps réel)}
Une tâche correspond à une sorte de programme, c'est à dire une série d'instructions 
qui doivent être exécutées par un processeur. 
Il y a plusieurs caractéristiques 
et propriétés qui définissent une tâche, que nous allons définir ici : 
\begin{itemize}
	\item[\textbf{Release Time}] : C'est le moment $t$ où une tâche $\tau$ peut commencer à être exécutée.
	\item[\textbf{Start, End}] : Le moment où la tâche commence effectivement à être exécutée, ou termine son exécution.
	\item[\textbf{Response Time\label{Response Time}}] : Temps maximum nécessaire à la réalisation de la tâche 
	entre le Release Time et End. %TODO vérif
	\item[\textbf{Deadline, temps limite}] : Correspond au temps limite au delà duquel la tâche doit avoir été exécutée. Il existe deux types de deadlines : 
	une absolue, et une relative. La deadline relative est une valeur fixe qui 
	est une propriété de la tâche, elle dépend donc du release time.\\
	La deadline absolue quant à elle est calculée avant l'exécution, et correspond 
	à un temps $t$ absolu.%TODO explain better, relire cours ptete ?!
	
	\item[\textbf{Worst Case Execution Time}] Afin de faciliter les calculs et l'abstraction du problème, l'on pose habituellement que le temps considéré d'exécution de 
	la tâche est le pire temps. Cela permet d'envisager le pire scénario, et ainsi 
	de s'assurer que si celui-ci est possible, alors dans de meilleures conditions, 
	la faisabilité est conservée. La notation utilisée dans le reste de ce document 
	est  \textbf{WCET} : \textbf{W}orst \textbf{C}ase \textbf{E}xecution \textbf{T}ime
	
	\item[\textbf{Laxité}] La laxité d'une tâche est la durée entre sa réalisation et son échéance. 
	Pour une tâche $\tau_i$, la laxité est :
	\begin{center}
		$L_i = D_i - C_i$
	\end{center}
\vspace{0.5cm}
	\item[\textbf{Tâches périodiques}]
	Une tâche périodique est une tâche qui génère régulièrement des jobs.  
Formellement, une tâche périodique est définie par un 4-uplet $(O, T, D, C)$ où 
\begin{itemize}
	\item[O] est l'"offset", c'est à dire le temps que met la tâche à générer un premier job.
	\item[T] est la période, c'est à dire le temps qui sépare deux générations de job par la tâche. 
	Comme le premier job est généré à l'instant $O$, alors $\forall i \in \{0, \infty \} t = O + i\times T$ 
	où $t$ est le temps où la tâche est générée la $i$ème fois.
	\item[D] est la deadline relative, c'est à dire le temps qui sépare au maximum la génération 
	d'un job et sa réalisation.
	\item[C] est le temps de réalisation. Dans les algorithmes, on utilise -- comme expliqué précédemment --
	le \textbf{WCET}.
\end{itemize}	
	Dans le cas de tâches périodiques, on distingue trois cas différents : \\
	\begin{enumerate}
		\item si l'échéance est égale à la période $\forall \tau_i, D_i = T_i$ : tâche à \label{echeancesurrequete}échéance sur requête
		\item si l'échéance est inférieure ou égale à la période $\forall \tau_i, D_i \leq T_i $ , on dit que la tâche est à \label{echeancecontrainte} échéance contrainte
		\item s'il n'y a pas de contrainte particulière, la tâche est dite "à échéance arbitraire".
	\end{enumerate}
	Les solutions d'ordonnancement pour ces trois types de tâches diffèrent donc. 
	Globalement, on peut ordonner ces trois types de tâches : \\
	échéance sur requêtes $\subset$ échéance contrainte $\subset$ échéance arbitraire.
	
	\item[\textbf{Tâche sporadique}] : Une tâche est sporadique est une tâche qui génère de nouveaux jobs, 
	comme dans le cas de la tâche périodique. 
	La différence entre ces deux types est que la tâche sporadique 
	génère deux jobs avec un intervalle de temps au moins égal à la durée correspondant à sa période, 
	et pas exactement égal. 
	
	\item[\textbf{Tâche apériodique}] : Pour ce type de tâches, on ignore la régularité de 
	l'arrivée de nouveaux jobs. Les propriétés du job ne sont connues que lorsqu'un job est 
	généré dans le système.
	
\end{itemize}

\subsection{Job}
Un job est une instance d'une tâche. %TODO fill...

\subsection{Ordonnanceur}
Un ordonnanceur (Scheduler) est la partie logicielle de 
l'OS chargée d'orchestrer l'ordre d'exécution des tâches du système 
selon des priorités fixées à l'avance ou durant l'exécution. 
On distingue trois types d'assignation de priorités des ordonnanceurs : \\
\begin{enumerate}
	\item Priorité fixée au niveau des tâches : Ce type d'ordonnanceur fixe la priorité 
	avant l'exécution, et celle-ci dépend donc des attributs de la tâche. 
	Deux exemples d'ordonnanceurs de ce type seront présentés plus loin : Rate Monotonic et 
	Deadline Monotonic.
	\item Priorité fixe au niveau des jobs : La priorité est fixée par l'ordonnanceur à l'arrivée du job 
	dans l'exécution, et elle ne peut pas changer jusqu'à la réalisation du job. Un exemple sera présenté plus loin : Earliest Deadline First.
	\item Priorité dynamique : L'ordonnanceur peut recalculer à tout moment de l'exécution 
	la priorité du job avec un exemple connu, Least Laxity First %TODO add ref
\end{enumerate}
	
Selon les cas, l'ordonnanceur peut avoir à gérer un seul processeur. Dans ce 
document, on parlera dans ce cas d'ordonnanceur mono-processeur. Toutefois, de plus en 
plus de systèmes possèdent plusieurs processeurs, et il existe deux grandes familles 
d'ordonnanceurs associés à ces systèmes : les Partitionnés, ou les Globaux. \\

%\subsection{En ligne, hors ligne}
%TODO blabla

\subsubsection{Ordonnanceur multi-processeur Partitionné}
Dans ce cas de figure, un traitement hors ligne aura permis de diviser/partitionner 
les tâches en des ensembles selon certaines propriétés. Par la suite, le traitement 
est similaire à un ordonnanceur mono-processeur.

\subsubsection{Ordonnanceur multi-processeur Global}
Ici, le traitement "idéal" se fait en ligne entièrement, le système gère directement 
plusieurs processeurs et un système de tâches. Ces ordonnanceurs sont par 
conséquents plus complexes, et par ailleurs, comme il a été précisé plus haut dans 
ce document, l'ordonnanceur global qui peut orchestrer n'importe quel ensemble de 
tâche optimal n'existe pas.

Dans la littérature, on décrit des ordonnanceurs dont une partie du travail se fait 
hors ligne (RUN) %TODO add ref
et on parle alors d'ordonnanceur "hybride".
	
\subsection{Préemption et hypothèse} 
Un système est dit préemptif s'il a la capacité 
	de mettre l'exécution d'un job en pause et d'exécuter un autre à la place. 
	Une hypothèse pour simplifier la question théorique des ordonnanceur est 
	très souvent faite dans la littérature : on considère le temps de 
	préemption comme nul. Cette hypothèse est bien entendu fausse, et il faudra 
	en tenir compte, particulièrement dans ce travail où l'on tente de faire 
	le lien entre la théorie et la mise en pratique. 

\subsection{Utilisation}
Le facteur d'utilisation $U_i$ d'une tâche périodique $\tau_i$ est le rapport entre 
son temps d'exécution et sa période. Par exemple, pour une tâche $\tau_i$ tel que 
$WCET = 50 ms$ et $T = 30 ms$, le processeur doit allouer $\frac{30}{50}$ du temps 
total d'exécution à cette tâche.\\

L'utilisation (ou le facteur d'utilisation) d'un système périodique est la proportion de temps 
passée par le processeur à l'exécution de tâches d'un système donné. 
Le calcul de l'utilisation permet dans certains cas et certaines conditions de donner une indication 
à propos de la faisabilité du système par un certain ordonnanceur. 
\\

Liu et Layland \cite{liulayland} en donnent une définition formelle dans leur article décrivant 
l'ordonnanceur \textbf{Rate Monotonic} (présenté plus tard dans ce document).\\ 

Soit $C_i$ le temps d'exécution d'une tâche $\tau_i$, et soit $T_i$ sa période, voici la définition de 
l'utilisation pour un système de $m$ tâches :\\
\begin{center}
	$U_{tot} = \sum_{i = 1}^{m}(\frac{C_i}{T_i})$
\end{center}


\subsection{Représentation graphique d'un système}
%TODO fill with an example. Hope not to have to draw it in latex :/
% http://martin-kumm.de/wiki/doku.php?id=Projects:A_LaTeX_package_for_gantt_plots
\begin{ganttchart}[vgrid, hgrid]{1}{15}
	\ganttbar{$\tau_1$}{7}{9}\\
	\ganttbar{$\tau_2$}{2}{4}\\
	\ganttbar{$\tau_3$}{5}{6}\\
	\ganttbar{$\tau_4$}{10}{10}\\
	\ganttbar{$\tau_5$}{11}{13}
\end{ganttchart}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% ETAT DE L'ART %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%
%
%%%%%%%%%%%%%%%%%
%\part{Si du moins votre travail est divisé en parties}
%%%%%%%%%%%%%%%%%
\chapter{État de l'art}
\newtheorem{defi}{Déf.}

La littérature sur le sujet des ordonnanceurs est assez vaste. 
Ceux-ci sont composés principalement de trois grandes familles :\\
\begin{itemize}
	\item Les mono-processeurs
	\item Les multi-processeurs Partitionnés
	\item Les multiprocesseurs Globaux
\end{itemize}
Les ordonnanceurs mon-processeurs étant plus simples à appréhender, nous commencerons 
par présenter cette famille.

\section{Ordonnanceurs mono processeur}

\subsection{Rate Monotonic}
L'ordonnanceur \textbf{R}ate \textbf{M}onotonic (RM) est décrit la première fois par Liu et Layland \cite{liulayland} en 1973. C'est 
donc un ordonnanceur classique, bien connu, ainsi que largement documenté [\cite{omarkermia}]. 
On considère un ensemble de tâches périodiques et indépendantes.
Les priorités sont statiques et attribuées en fonction de la durée de la période, ainsi 
la tâche avec la période la plus faible sera de priorité plus élevée. 
Un des points fondamentaux de l'article est de prouver l'optimalité de RM dans le cas de tâches 
préemptives, périodiques (à échéance sur requête), indépendantes, simultanées.
Les auteurs énoncent même une condition suffisante de faisabilité pour un système à $m$ tâches : \\
\begin{center}
	$\sum_{i=1}^{m}\frac{C_i}{T_i} \leq m(2^{\frac{1}{m}}-1)$
\end{center}
Notons également que pour $n \rightarrow \infty$, $\sum_{i=1}^{m}\frac{C_i}{T_i} \leq m(2^{\frac{1}{m}}-1) \rightarrow \ln(2) \approx 0.69$.
Une condition suffisante est donc que le facteur d'utilisation du système soit inférieur à 0.69. 
Dans ce cas, le système est ordonnançable par RM.\\

Des améliorations ont par la suite été apportées par Joseph et Pandya \cite{DBLP}.
qui ont trouvé une condition nécessaire et suffisante. 
Ainsi, si $RT(t_i)$ est le Response Time (\ref{Response Time}) d'une tâche $t_i$, 
alors si un ensemble de tâches périodiques est trié par ordre décroissant, l'équation suivante 
définit la borne supérieure du Release Time :
\begin{center}
	$RT(t_i)^{q+1} = \sum_{j=1}^{i-1} \lceil \frac{RT(t_i)^q}{T(t_i)} \rceil \times C(t_j)) + C(t_i)$
\end{center}
Le système est ordonnançable si et seulement si $\forall i_{(1 \leq i \leq m)}RT(t_i) \leq T_i$.
On pourra résoudre récursivement cette équation afin de prouver sa faisabilité.\\

RM n'est cependant optimal que pour cette classe de tâches. Dès que les propriétés changent, 
il faudra se tourner vers un autre type d'ordonnanceur.


\subsection{Deadline Monotonic}
Deadline Monotonic (DM) est un ordonnanceur pour les systèmes à départ simultanés ($offset = 0$) et 
à échéance contrainte\ref{echeancecontrainte}($D_i \leq T_i$). Il a été décrit par Leung et Whitehead 
\cite{LeungW82}. Cet article aborde le point de vue mono-processeur et multi-processeur partitionné, 
dont il sera question plus loin dans ce document.\\

Avec cet ordonnanceur, les priorités sont fixes, au niveau des tâches.
Plus la deadline est petite, plus la priorité est élevée. On peut considérer que RM est 
un cas particulier de DM, puisque pour RM, les tâches sont à échéance sur requête \ref{echeancesurrequete}.
Il n'existe pas de test de faisabilité basé sur l'utilisation du système. Pour vérifier celle-ci, 
il faut avoir recours à l'équation décrite plus haut. 
On peut la résoudre récursivement à l'aide de ce système : \\
\begin{enumerate}
	\item $W_0 = C_i $
	\item $W_{k+1} = C_i + \sum_{j = 1}^{i-1}\lceil \frac{W_k}{T_j} \rceil \times C_j $
\end{enumerate}



\subsection{Earliest Deadline First}
\cite{ndoye}
\textbf{E}arliest \textbf{D}eadline \textbf{F}irst (EDF) est un ordonnanceur 
qui a été introduit e 1973, à la même période que Rate Monotonic, également 
par Lui et Layland \cite{liulayland}. C'est un ordonnanceur à départ différé ($Offset \neq 0$) 
et à deadline arbitraire (pas de contrainte sur la deadline par rapport à la période), 
qui fixe les priorités sur les jobs. L'assignation de la priorité se fait sur base de 
la proximité de la deadline absolue : Plus cette deadline est proche et plus la priorité est élevée. 
Une façon déterministe et arbitraire de régler les cas d'égalité doit être décidée.\\

EDF est optimal pour toutes les tâches synchrones et asynchrones, avec et sans 
contraintes sur les deadlines. 
Cela signifie que si un système est ordonnançable, EDF peut l'ordonnancer.\\
Cette propriété est importante, car les classes de tâches ordonnancées par EDF 
sont plus larges que RM et DM, par conséquent, EDF peut ordonnancer également les 
mêmes classes qu'RM et DM en conservant son optimalité. \\

Les tests de faisabilités avec EDF dépendent de la classe de tâche considérée. 
Pour un système synchrone et à échéance sur requête, 
une condition nécessaire et suffisante de faisabilité est donc que l'utilisation soit inférieure 
à 100\%, c'est à dire : \\
\begin{center}
	$\forall \tau_i \in \Gamma_m, \sum_{i=1}^{m}\frac{C_i}{T_i} \leq 1 $
\end{center}

Dans le cas d'un système synchrone à échéance arbitraire, on doit considérer un intervalle de 
recherche $[0, L]$ avec $L$ qui peut se calculer de façon itérative en cherchant un point fixe 
avec cette formule : \\
\[
\left \{
\begin{array}{r l}
W_0 &= \sum_{i = 1}^{m}C_i\\
W_{k+1} & =\sum_{i = 1}^{m} \lceil \frac{W_k}{T_i} \rceil \times C_i
\end{array}
\right.
\]

Dans le cas des systèmes de tâches asynchrones, l'intervalle considéré est plus grand : 
$[0, O_{max} + 2 \times P]$ avec $O_{max}$ l'offset maximum du système et 
$P$ le plus petit commun multiple ($ppcm$) de toutes les périodes du système, soit : \\
\begin{center}
	$P = ppcm\{T_i | i \in \{1, ... m\}\}$
\end{center}

\section{Multi-processeurs partitionnés}

%TODO revoir cours de goossens

Dans la partie précédente, nous avons présenté certains algorithmes mono-processeur, 
ainsi que quelques conditions d'ordonnançabilité.
De nos jours, une grande partie des architectures employées dans un système embarqué 
est multiprocesseur. Les stratégies mises en place pour l'ordonnancement de tels 
systèmes sont différentes, il n'est pas suffisant de conserver les mêmes solutions 
et de les appliquer à plusieurs processeurs.\\
 
Afin d'exécuter les tâches sur différents processeurs, plusieurs stratégies existent, 
dont l'une dite de \textit{partitionnement}. 
Cette stratégie consiste à diviser l'ensemble de tâches en sous-ensembles qui seront 
attribués à un processeur particulier. Cela permet de conserver les mêmes algorithmes ainsi 
que tests d'ordonnançabilité que ceux 
décrits précédemment puisqu'en divisant le système en sous-systèmes attribués à un 
processeur chacun, cela revient à appliquer "localement" une stratégie mono-processeur, contre 
une stratégie globale multi-processeur \cite{ndoye_ordonnancement_2014}.
%TODO add formal def

Concrètement, cela revient à diviser un ensemble $\Gamma$ de tâches en $n$ sous-ensembles 
$\gamma \in \Gamma$ et d'attribuer à chacun des $m$ processeurs un de ces sous-ensembles $\gamma$.\\

Le problème du partitionnement consiste donc en premier lieu 
à résoudre une division du système en sous-systèmes, ce qui est connu dans la 
littérature scientifique comme le problème du bin-packing \cite{ausiello_approximation_1984}.
Ce problème appartient à la classe de complexité $NP$, si bien qu'en pratique, 
des heuristiques sont appliquées, comme par exemple :\\
\begin{itemize}
	\item First-fit 
	\item Best-fit
	\item Next-fit
\end{itemize}

%TODO insert test faisabilité ssi multiproc
%TODO insert ref vers non conservation faisabilité multiproc

Plusieurs algorithmes de ce type ont été présentés dans la littérature scientifique, 
dès les années 80 comme par exemple 


Un des problèmes étant que ces solutions ne garantissent pas la solution optimale, puisque ce sont 
des heuristiques. Un autre problème important étant que dans le processus partitionné, une tâche est 
assignée à un processeur, mais ne pourra pas être assignée à plusieurs. Ainsi, si des solutions 
existent qui consistent à migrer une tâche sur un autre processeur, elle ne pourra pas être trouvée 
par un ordonnanceur partitionné \cite{ramamurthy_static-priority_2000}. %TODO cite Static-Priority Periodic Scheduling on Multiprocessor Mark Moir
Enfin, une autre limite est que ce processus ne permet pas à une tâche d'évoluer avec le temps. 
Le mode doit être décidé avant l'exécution, et devra être fixé une fois pour toutes. 
Cela peut convenir à un certain nombre de systèmes, mais ne peut pas être une solution générale.\\

%Des études ont montré que les ordonnanceurs globaux basés sur \textbf{RM} et \textbf{DM} 
%tendaient à avoir une  plus faible utilisation que les ordonnanceurs partitionnés. 
%TODO citer  Baruah et al. [4, 5] ?!
% citer ndoye, oui !

\section{Multi-processeurs globaux}
Une autre façon d'ordonnancer plusieurs processeurs est de ne pas procéder à un partitionnement préalable, 
et donc, de gérer tous les processeurs en même temps. 
Les deux façons de procéder ne sont pas comparables. Pourquoi ?
--> parler de il n'existe pas de scheduler non clairvoyant optimal.
Résultat super important, cité avant.\\

Donc il n'existe pas de test qui permette de savoir si on peut ordonnancer 
un système sur partionned ou global.

Ca signifie qu'il faut essayer de le faire... Simuler.

Problèmeh : les deux façons de procéder sont incomparables. Pourquoi ? Issu du cours, montrer 
un système schedulable en partionned et pas en global et vice et versa.

Grande idée : il existe PAS de scheduler idéal.
Du coup, il faut en chercher un qui a le plus grand système de tâche possible, ou du moins, 
le plus intéressant. 

Parmi ceux-ci, il y a : 

\subsection{EDF-k}
\subsection{DP-WRAP}
\subsection{RUN}
\subsection{U-EDF}


\section{Conclusion}
% tableau ? Support pour développer argumentation ?

Ici, je fais le résumé des algos dont on a parlé précédemment et je construis un tableau récapitulatif. 

\bibliographystyle{plain}
\bibliography{bibzotero}

\end{document}


